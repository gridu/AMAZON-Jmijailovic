{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from hashlib import md5\n",
    "\n",
    "if sys.version_info < (3,):\n",
    "    maketrans = string.maketrans\n",
    "else:\n",
    "    maketrans = str.maketrans\n",
    "    \n",
    "def vectorize_sequences(sequences, vocabulary_length):\n",
    "    results = np.zeros((len(sequences), vocabulary_length))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "       results[i, sequence] = 1. \n",
    "    return results\n",
    "\n",
    "def one_hot_encode(messages, vocabulary_length):\n",
    "    data = []\n",
    "    for msg in messages:\n",
    "        temp = one_hot(msg, vocabulary_length)\n",
    "        data.append(temp)\n",
    "    return data\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    \"\"\"Converts a text to a sequence of words (or tokens).\n",
    "    # Arguments\n",
    "        text: Input text (string).\n",
    "        filters: list (or concatenation) of characters to filter out, such as\n",
    "            punctuation. Default: `!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n`,\n",
    "            includes basic punctuation, tabs, and newlines.\n",
    "        lower: boolean. Whether to convert the input to lowercase.\n",
    "        split: str. Separator for word splitting.\n",
    "    # Returns\n",
    "        A list of words (or tokens).\n",
    "    \"\"\"\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "\n",
    "    if sys.version_info < (3,):\n",
    "        if isinstance(text, unicode):\n",
    "            translate_map = dict((ord(c), unicode(split)) for c in filters)\n",
    "            text = text.translate(translate_map)\n",
    "        elif len(split) == 1:\n",
    "            translate_map = maketrans(filters, split * len(filters))\n",
    "            text = text.translate(translate_map)\n",
    "        else:\n",
    "            for c in filters:\n",
    "                text = text.replace(c, split)\n",
    "    else:\n",
    "        translate_dict = dict((c, split) for c in filters)\n",
    "        translate_map = maketrans(translate_dict)\n",
    "        text = text.translate(translate_map)\n",
    "\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "\n",
    "def one_hot(text, n,\n",
    "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "            lower=True,\n",
    "            split=' '):\n",
    "    \"\"\"One-hot encodes a text into a list of word indexes of size n.\n",
    "    This is a wrapper to the `hashing_trick` function using `hash` as the\n",
    "    hashing function; unicity of word to index mapping non-guaranteed.\n",
    "    # Arguments\n",
    "        text: Input text (string).\n",
    "        n: int. Size of vocabulary.\n",
    "        filters: list (or concatenation) of characters to filter out, such as\n",
    "            punctuation. Default: `!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n`,\n",
    "            includes basic punctuation, tabs, and newlines.\n",
    "        lower: boolean. Whether to set the text to lowercase.\n",
    "        split: str. Separator for word splitting.\n",
    "    # Returns\n",
    "        List of integers in [1, n]. Each integer encodes a word\n",
    "        (unicity non-guaranteed).\n",
    "    \"\"\"\n",
    "    return hashing_trick(text, n,\n",
    "                         hash_function='md5',\n",
    "                         filters=filters,\n",
    "                         lower=lower,\n",
    "                         split=split)\n",
    "\n",
    "\n",
    "def hashing_trick(text, n,\n",
    "                  hash_function=None,\n",
    "                  filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                  lower=True,\n",
    "                  split=' '):\n",
    "    \"\"\"Converts a text to a sequence of indexes in a fixed-size hashing space.\n",
    "    # Arguments\n",
    "        text: Input text (string).\n",
    "        n: Dimension of the hashing space.\n",
    "        hash_function: defaults to python `hash` function, can be 'md5' or\n",
    "            any function that takes in input a string and returns a int.\n",
    "            Note that 'hash' is not a stable hashing function, so\n",
    "            it is not consistent across different runs, while 'md5'\n",
    "            is a stable hashing function.\n",
    "        filters: list (or concatenation) of characters to filter out, such as\n",
    "            punctuation. Default: `!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n`,\n",
    "            includes basic punctuation, tabs, and newlines.\n",
    "        lower: boolean. Whether to set the text to lowercase.\n",
    "        split: str. Separator for word splitting.\n",
    "    # Returns\n",
    "        A list of integer word indices (unicity non-guaranteed).\n",
    "    `0` is a reserved index that won't be assigned to any word.\n",
    "    Two or more words may be assigned to the same index, due to possible\n",
    "    collisions by the hashing function.\n",
    "    The [probability](\n",
    "        https://en.wikipedia.org/wiki/Birthday_problem#Probability_table)\n",
    "    of a collision is in relation to the dimension of the hashing space and\n",
    "    the number of distinct objects.\n",
    "    \"\"\"\n",
    "    if hash_function is None:\n",
    "        hash_function = hash\n",
    "    elif hash_function == 'md5':\n",
    "        hash_function = lambda w: int(md5(w.encode()).hexdigest(), 16)\n",
    "\n",
    "    seq = text_to_word_sequence(text,\n",
    "                                filters=filters,\n",
    "                                lower=lower,\n",
    "                                split=split)\n",
    "    return [int(hash_function(w) % (n - 1) + 1) for w in seq]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
